{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7694fa3d-ab3e-427f-bb73-a34cd83a6610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions\n",
    "# OS interaction and time\n",
    "import os\n",
    "import sys\n",
    "import cftime\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "import dask\n",
    "import dask.bag as db\n",
    "import calendar\n",
    "\n",
    "# math and data\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import pickle as pickle\n",
    "from sklearn import linear_model\n",
    "import matplotlib.patches as mpatches\n",
    "from shapely.geometry.polygon import LinearRing\n",
    "import statsmodels.stats.multitest as multitest\n",
    "\n",
    "# plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from mpl_toolkits.axes_grid1.axes_divider import HBoxDivider\n",
    "import mpl_toolkits.axes_grid1.axes_size as Size\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.util import add_cyclic_point\n",
    "\n",
    "# random\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "import IPython.core.display as di # Example: di.display_html('<h3>%s:</h3>' % str, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "052e09d6-afd8-424d-a2db-c6c581c6f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in_path = '/glade/u/home/zcleveland/scratch/ERA5/dsw/'  # path to subsetted data\n",
    "sub_script_path = '/glade/u/home/zcleveland/NAM_soil-moisture/ERA5_analysis/scripts/subsetting/'  # path to subsetting scripts\n",
    "plot_script_path = '/glade/u/home/zcleveland/NAM_soil-moisture/ERA5_analysis/scripts/plotting/'  # path to plotting scripts\n",
    "fig_out_path = '/glade/u/home/zcleveland/NAM_soil-moisture/ERA5_analysis/plots/' # path to generated figures\n",
    "temp_scratch_path = '/glade/u/home/zcleveland/NAM_soil-moisture/ERA5_analysis/temp/'  # path to temp directory in scratch\n",
    "derived_script_path = '/glade/u/home/zcleveland/NAM_soil-moisture/ERA5_analysis/scripts/derived/'  # path to derived scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37482965-703f-4d57-881f-22cac80d2566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable list to choose\n",
    "var_list = [\n",
    "    # 'lsp', # large scale precipitation (m of water) - accumu\n",
    "    # 'cp', # convective precipitation (m of water) - accumu\n",
    "    # 'tp', # total precipitation (m of water) - accumu -- DERIVED\n",
    "    # 'sd', # snow depth  (m of water equivalent) - instan\n",
    "    # 'msl', # mean sea level pressure (Pa) - instan\n",
    "    # 'tcc', # total cloud cover (0-1) - instan\n",
    "    # 'stl1', # soil temp layer 1 (K) - instan\n",
    "    # 'stl2', # soil temp layer 2 (K) - instan\n",
    "    # 'stl3', # soil temp layer 3 (K) - instan\n",
    "    # 'stl4', # soil temp layer 4 (K) - instan\n",
    "    # 'swvl1', # soil volume water content layer 1 (m^3 m^-3) - instan\n",
    "    # 'swvl2', # soil volume water content layer 2 (m^3 m^-3) - instan\n",
    "    # 'swvl3', # soil volume water content layer 3 (m^3 m^-3) - instan\n",
    "    # 'swvl4', # soil volume water content layer 4 (m^3 m^-3) - instan\n",
    "    # '2t', # 2 meter temp (K) - instan\n",
    "    # '2d', # 2 meter dew point (K) - instan\n",
    "    # 'ishf', # instant surface heat flux (W m^-2) - instan\n",
    "    # 'ie', # instant moisture flux (kg m^-2 s^-1) - instan\n",
    "    # 'sshf', # surface sensible heat flux (J m^-2) - accumu\n",
    "    # 'slhf', # surface latent heat flux (J m^-2) - accumu\n",
    "    # 'ssr', # surface net solar radiation (J m^-2) - accumu\n",
    "    # 'str', # surface net thermal radiation (J m^-2) - accumu\n",
    "    # 'sro', # surface runoff (m) - accumu\n",
    "    # 'sf', # total snowfall (m of water equivalent) - accumu\n",
    "    # 'cape', # convective available potential energy (J kg^-1) - instan\n",
    "    'tcw',  # total column water (kg m^-2) - sfc (sum of solid/liquid/vapor)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5801b8c9-5d6d-436b-926c-c0bda8ab04bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open datasets for calculating onset timing\n",
    "\n",
    "# total water content stats\n",
    "tcw_max = xr.open_dataset(f'{data_in_path}tcw_max_stats.nc')\n",
    "tcw_min = xr.open_dataset(f'{data_in_path}tcw_min_stats.nc')\n",
    "\n",
    "# the average of the annual max/min daily total water content values\n",
    "pw_max = tcw_max['MEAN']\n",
    "pw_min = tcw_min['MEAN']\n",
    "\n",
    "# daily tcw values\n",
    "files = glob.glob(f'{data_in_path}*/tcw_*_dsw.nc')\n",
    "files.sort()\n",
    "\n",
    "# open files and pull out daily average\n",
    "tcw = xr.open_mfdataset(files)\n",
    "tcw = tcw['TCW_AVG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c8f3a-6653-44f3-bc31-e69663d3a42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate onset date using methods of Zeng and Lu 2004\n",
    "\n",
    "# normalized precipitable water index\n",
    "npwi = (tcw-pw_min)/(pw_max-pw_min)\n",
    "\n",
    "# set a threshold of 2*pi/10\n",
    "threshold = 2*np.pi/10\n",
    "\n",
    "\n",
    "# create mask for when npwi values exceed threshold\n",
    "def onset_condition(da):\n",
    "    # create a boolean mask where npwi exceeds the threshold\n",
    "    mask = da > threshold\n",
    "\n",
    "    # use rolling window of 3 along the time dimension and check if  True\n",
    "    # return mask\n",
    "    return mask.rolling(time=3).sum() >= 3\n",
    "\n",
    "\n",
    "# apply onset condition across time dimension\n",
    "onset_mask = npwi.groupby('time.year').apply(onset_condition)\n",
    "\n",
    "# generate empty dataset to store onset times\n",
    "onset_time = xr.Dataset(\n",
    "    coords={\n",
    "        'year': pd.date_range(start='1980-01-01', end='2019-01-01', freq='YS'),\n",
    "        'latitude': npwi.latitude.values,\n",
    "        'longitude': npwi.longitude.values\n",
    "    }\n",
    ")\n",
    "# generate empty dataset to store retreat times\n",
    "retreat_time = xr.Dataset(\n",
    "    coords={\n",
    "        'year': pd.date_range(start='1980-01-01', end='2019-01-01', freq='YS'),\n",
    "        'latitude': npwi.latitude.values,\n",
    "        'longitude': npwi.longitude.values\n",
    "    }\n",
    ")\n",
    "# create date variable\n",
    "dates1 = np.empty((40, 81, 81), dtype='datetime64[ns]')\n",
    "dates2 = np.empty((40, 81, 81), dtype='datetime64[ns]')\n",
    "dates1[:] = np.datetime64('NaT')  # store NaT values at temporary place holders\n",
    "dates2[:] = np.datetime64('NaT')  # store NaT values at temporary place holders\n",
    "onset_time['date'] = (('year', 'latitude', 'longitude'), dates1)\n",
    "retreat_time['date'] = (('year', 'latitude', 'longitude'), dates2)\n",
    "times = npwi.time\n",
    "\n",
    "for year in range(1980, 2020):\n",
    "    with open(f'{derived_script_path}onset_retreat.txt', 'a') as file:\n",
    "        file.write(f'\\n\\nyear: {year}\\nlat: ')\n",
    "    # print(f'\\n\\nYear: {year}')\n",
    "    temp_times = times.sel(time=str(year))\n",
    "    for lat in npwi.latitude:\n",
    "        # print('\\n', end='')\n",
    "        if (lat % 1 == 0):\n",
    "            with open(f'{derived_script_path}onset_retreat.txt', 'a') as file:\n",
    "                file.write(f'{int(lat.values)}... ')\n",
    "            # print(f'\\nLat: {int(lat.values)} \\nLon: ')\n",
    "        for lon in npwi.longitude:\n",
    "            # if (lon % 5 == 0):\n",
    "            #     print(f'{int(lon.values)} ... ', end='')\n",
    "\n",
    "            temp_mask = onset_mask.sel(time=str(year), latitude=lat, longitude=lon)\n",
    "            temp_idx = np.where(temp_mask)\n",
    "            temp_onset_coord = {'year': str(year), 'latitude': lat, 'longitude': lon}\n",
    "            temp_retreat_coord = {'year': str(year), 'latitude': lat, 'longitude': lon}\n",
    "\n",
    "            if temp_idx[0].size>0:\n",
    "                temp_onset_time = temp_times[temp_idx[0][0] - 2]  # subtract 2 to get 1st index\n",
    "                temp_retreat_time = temp_times[temp_idx[0][-1]]  # last index\n",
    "            else:\n",
    "                temp_onset_time = np.nan\n",
    "                temp_retreat_time = np.nan\n",
    "\n",
    "            onset_time['date'].loc[temp_onset_coord] = temp_onset_time\n",
    "            retreat_time['date'].loc[temp_retreat_coord] = temp_retreat_time\n",
    "\n",
    "# save as netcdf\n",
    "onset_time.to_netcdf(f'{data_in_path}NAM_onset.nc')\n",
    "retreat_time.to_netcdf(f'{data_in_path}NAM_retreat.nc')\n",
    "\n",
    "with open(f'{derived_script_path}onset_retreat.txt', 'a') as file:\n",
    "    file.write('\\n\\nDone')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a9cb91b-462f-4b62-ae27-72d3f9e79e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to calculate onset and retreat trends\n",
    "def calc_onset_trend(start_year, end_year):\n",
    "\n",
    "    # open datasets\n",
    "    onset_ds = xr.open_dataset(os.path.join(data_in_path, 'NAM_onset.nc'))\n",
    "    retreat_ds = xr.open_dataset(os.path.join(data_in_path, 'NAM_retreat.nc'))\n",
    "\n",
    "    # extract time frame\n",
    "    onset_time = onset_ds['date'].sel(year=slice(str(start_year), str(end_year)), drop=True)\n",
    "    retreat_time = retreat_ds['date'].sel(year=slice(str(start_year), str(end_year)), drop=True)\n",
    "\n",
    "    # close datasets\n",
    "    onset_ds.close()\n",
    "    retreat_ds.close()\n",
    "\n",
    "    # convert from datetime to ordinal day\n",
    "    onset_day = onset_time.dt.dayofyear\n",
    "    retreat_day = retreat_time.dt.dayofyear\n",
    "    # compute length of NAM\n",
    "    NAM_length = retreat_day - onset_day\n",
    "\n",
    "    # compute mean\n",
    "    onset_mean = np.floor(onset_day.mean(dim='year'))\n",
    "    retreat_mean = np.floor(retreat_day.mean(dim='year'))\n",
    "    NAM_length_mean = retreat_mean - onset_mean\n",
    "\n",
    "    # compute the gradient\n",
    "    onset_grad = onset_day.diff('year')\n",
    "    retreat_grad = retreat_day.diff('year')\n",
    "    NAM_length_grad = NAM_length.diff('year')\n",
    "\n",
    "    # compute mean gradients\n",
    "    mean_onset_grad = onset_grad.mean(dim='year')\n",
    "    mean_retreat_grad = retreat_grad.mean(dim='year')\n",
    "    mean_NAM_length_grad = NAM_length_grad.mean(dim='year')\n",
    "\n",
    "    # save all to netcdf\n",
    "    # onset\n",
    "    onset_mean.to_netcdf(f'{data_in_path}NAM_onset_mean.nc')\n",
    "    onset_grad.to_netcdf(f'{data_in_path}onset_gradient.nc')\n",
    "    mean_onset_grad.to_netcdf(f'{data_in_path}onset_mean_gradient.nc')\n",
    "\n",
    "    # retreat\n",
    "    retreat_mean.to_netcdf(f'{data_in_path}NAM_retreat_mean.nc')\n",
    "    retreat_grad.to_netcdf(f'{data_in_path}retreat_gradient.nc')\n",
    "    mean_retreat_grad.to_netcdf(f'{data_in_path}retreat_mean_gradient.nc')\n",
    "\n",
    "    # NAM length\n",
    "    NAM_length.to_netcdf(f'{data_in_path}NAM_length.nc')\n",
    "    NAM_length_mean.to_netcdf(f'{data_in_path}NAM_length_mean.nc')\n",
    "    NAM_length_grad.to_netcdf(f'{data_in_path}NAM_length_gradient.nc')\n",
    "    mean_NAM_length_grad.to_netcdf(f'{data_in_path}mean_NAM_length_gradient.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f95c7861-6a1c-4906-9d44-070e149ad0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    calc_onset_trend(1980,2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e438b4e-3242-4f9a-ba03-d5d9cb4040b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-mland_xr]",
   "language": "python",
   "name": "conda-env-.conda-mland_xr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
