{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5798e527-e727-4567-8ecf-06a6952c44c1",
   "metadata": {},
   "source": [
    "This script calculates correlations between various parameters and saves them to their own netcdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e91cac-5dc0-42b4-8cbd-3c8f6d034186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions\n",
    "# OS interaction and time\n",
    "import os\n",
    "import sys\n",
    "import cftime\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "import dask\n",
    "import dask.bag as db\n",
    "import calendar\n",
    "\n",
    "# math and data\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import pickle as pickle\n",
    "from sklearn import linear_model\n",
    "import matplotlib.patches as mpatches\n",
    "from shapely.geometry.polygon import LinearRing\n",
    "import statsmodels.stats.multitest as multitest\n",
    "\n",
    "# plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from mpl_toolkits.axes_grid1.axes_divider import HBoxDivider\n",
    "import mpl_toolkits.axes_grid1.axes_size as Size\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.util import add_cyclic_point\n",
    "\n",
    "# random\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "import IPython.core.display as di # Example: di.display_html('<h3>%s:</h3>' % str, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1e2374b-e37c-4847-a068-424e6a656799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify directories\n",
    "my_era5_path = '/glade/u/home/zcleveland/scratch/ERA5/'  # path to subset data\n",
    "cp_in_path = '/glade/u/home/zcleveland/scratch/ERA5/cp/'  # path to subset CP data\n",
    "corr_out_path = '/glade/u/home/zcleveland/scratch/ERA5/correlations/'  # path to correlation calculation folder\n",
    "sub_script_path = '/glade/u/home/zcleveland/NAM_soil-moisture/ERA5_analysis/scripts/subsetting/'  # path to subsetting scripts\n",
    "der_script_path = '/glade/u/home/zcleveland/NAM_soil-moisture/ERA5_analysis/scripts/derived/'  # path to derived scripts\n",
    "plot_script_path = '/glade/u/home/zcleveland/NAM_soil-moisture/ERA5_analysis/scripts/plotting/'  # path to plotting scripts\n",
    "fig_out_path = '/glade/u/home/zcleveland/NAM_soil-moisture/ERA5_analysis/plots/'  # path to generated figures\n",
    "temp_scratch_path = '/glade/u/home/zcleveland/NAM_soil-moisture/ERA5_analysis/temp/'  # path to temp directory in scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9e9b7b5-3fc5-43f3-bf8f-5754e84a9f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define list of variables\n",
    "var_list = [\n",
    "    'lsp',  # large scale precipitation (m of water) - accumu\n",
    "    'cp',  # convective precipitation (m of water) - accumu\n",
    "    'tp',  # total precipitation (m of water) - accumu -- DERIVED\n",
    "    'sd',  # snow depth  (m of water equivalent) - instan\n",
    "    'msl',  # mean sea level pressure (Pa) - instan\n",
    "    'tcc',  # total cloud cover (0-1) - instan\n",
    "    'stl1',  # soil temp layer 1 (K) - instan\n",
    "    'stl2',  # soil temp layer 2 (K) - instan\n",
    "    'stl3',  # soil temp layer 3 (K) - instan\n",
    "    'stl4',  # soil temp layer 4 (K) - instan\n",
    "    'swvl1',  # soil volume water content layer 1 (m^3 m^-3) - instan\n",
    "    'swvl2',  # soil volume water content layer 2 (m^3 m^-3) - instan\n",
    "    'swvl3',  # soil volume water content layer 3 (m^3 m^-3) - instan\n",
    "    'swvl4',  # soil volume water content layer 4 (m^3 m^-3) - instan\n",
    "    '2t',  # 2 meter temp (K) - instan\n",
    "    '2d',  # 2 meter dew point (K) - instan\n",
    "    'ishf',  # instant surface heat flux (W m^-2) - instan\n",
    "    'ie',  # instant moisture flux (kg m^-2 s^-1) - instan\n",
    "    'sshf',  # surface sensible heat flux (J m^-2) - accumu\n",
    "    'slhf',  # surface latent heat flux (J m^-2) - accumu\n",
    "    'ssr',  # surface net solar radiation (J m^-2) - accumu\n",
    "    'str',  # surface net thermal radiation (J m^-2) - accumu\n",
    "    'sro',  # surface runoff (m) - accumu\n",
    "    'sf',  # total snowfall (m of water equivalent) - accumu\n",
    "    'cape',  # convective available potential energy (J kg^-1) - instan\n",
    "    'tcw',  # total column water (kg m^-2) - sfc (sum total of solid, liquid, and vapor in a column)\n",
    "    'ssrd',  # surface solar radiation downwards (J m^-2) - accumu\n",
    "    'strd',  # surface thermal radiation downwards (J m^-2) - accumu\n",
    "    'ttr',  # top net thermal radiation (OLR, J m^-2) - accumu -- divide by time (s) for W m^-2\n",
    "    'sstk',  # sea surface temperature (K) - instan\n",
    "]\n",
    "\n",
    "NAM_var_list = [\n",
    "    'onset',\n",
    "    'retreat',\n",
    "    'length'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e148c87f-62c6-40d0-88c3-70c5d9aaded1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to calculate the correlation between\n",
    "# any given parameter and the NAM onset date\n",
    "def calc_correlation(NAM_var = 'onset', var='swvl1', months=[3, 4, 5], cp_flag=False):\n",
    "\n",
    "    # create string to make directory path for figure save\n",
    "    if cp_flag:\n",
    "        var_region = 'cp'\n",
    "    else:\n",
    "        var_region = 'dsw'\n",
    "\n",
    "    # create list of months over which to average\n",
    "    var_months_list = months  # [int(m) for m in str(months)]  # turn var integer into list (e.g. 678 -> [6,7,8])\n",
    "    # make string for month letters from var_range (e.g. [6,7,8] -> 'JJA')\n",
    "    var_months = ''.join([calendar.month_name[m][0] for m in var_months_list])\n",
    "\n",
    "    # path to save figures\n",
    "    out_fn = f'corr_{var}_{NAM_var}_{var_months}_{var_region}.nc'\n",
    "    out_fp = os.path.join(corr_out_path, var_region, out_fn)\n",
    "\n",
    "    # check existence of file already\n",
    "    if os.path.exists(out_fp):\n",
    "        print(f'File already exists for: {out_fn}')\n",
    "        print('\\nSkipping . . .')\n",
    "        return\n",
    "\n",
    "    # open onset dataset\n",
    "    NAM_ds = xr.open_dataset(os.path.join(my_era5_path, f'dsw/NAM_{NAM_var}.nc'))\n",
    "    NAM_ds['year'] = NAM_ds['year'].dt.year  # convert to only year.  e.g. 2012-01-01 -> 2012\n",
    "\n",
    "    # extract data array of the NAM variable\n",
    "    if NAM_var == 'length':\n",
    "        NAM_da = NAM_ds['dayofyear']\n",
    "        NAM_data = NAM_da.astype('float32')\n",
    "    else:\n",
    "        NAM_da = NAM_ds['date']\n",
    "        NAM_data = NAM_da.dt.dayofyear.astype('float32')\n",
    "\n",
    "    # open var dataset\n",
    "    if cp_flag:\n",
    "        var_files = glob.glob(f'{my_era5_path}{var_region}/*{var}_198001_201912_cp.nc')\n",
    "        if len(var_files) != 1:\n",
    "            print(f'Too many files for var_region: cp -- {len(var_files)}\\n')\n",
    "            print('Skipping . . .')\n",
    "            return\n",
    "    else:\n",
    "        var_files = glob.glob(f'{my_era5_path}{var_region}/*/*{var}_*_{var_region}.nc')\n",
    "        if len(var_files) != 40:\n",
    "            print(f'Too many files for var_region: cp -- {len(var_files)}\\n')\n",
    "            print('Skipping . . .')\n",
    "            return\n",
    "\n",
    "    var_ds = xr.open_mfdataset(var_files)\n",
    "\n",
    "    # pull out actual variable name in the dataset since they can be different names/capitalized\n",
    "    var_name = [v for v in var_ds.data_vars.keys() if f'{var.upper()}' in v][0]\n",
    "    var_da = var_ds[var_name]\n",
    "\n",
    "    # get data from var\n",
    "    if 'AVG' in var_name:\n",
    "        mon_mean = var_da.resample(time='1M').mean()\n",
    "        var_mon_mean = mon_mean.sel(time=mon_mean['time.month'].isin(var_months_list))\n",
    "        var_data = var_mon_mean.groupby('time.year').mean(dim='time')\n",
    "    else:\n",
    "        mon_sum = var_da.resample(time='1M').sum()\n",
    "        var_mon_sum = mon_sum.sel(time=mon_sum['time.month'].isin(var_months_list))\n",
    "        var_data = var_mon_sum.groupby('time.year').sum(dim='time')\n",
    "\n",
    "    # calculate correlation\n",
    "    var_corr = xr.corr(NAM_data, var_data, dim='year')\n",
    "\n",
    "    # save correlation as netcdf file\n",
    "    var_corr.to_netcdf(out_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8133e054-c674-4107-b409-053edd8cddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlations for dsw\n",
    "# for var in var_list:\n",
    "#     print(var, '\\n')\n",
    "#     for NAM_var in NAM_var_list:\n",
    "#         calc_correlation(NAM_var=NAM_var, var=var, months=[3, 4, 5], cp_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d57bdc1-8e29-45c6-9ba7-975e69a653df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlations for cp\n",
    "# for var in var_list:\n",
    "#     print(var, '\\n')\n",
    "#     for NAM_var in NAM_var_list:\n",
    "#         calc_correlation(NAM_var=NAM_var, var=var, months=[3, 4, 5], cp_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625da784-562e-4d69-8969-533c209f6e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation between onset and summer precip\n",
    "# for NAM_var in NAM_var_list:\n",
    "#     calc_correlation(NAM_var=NAM_var, var='tp', months=[6, 7, 8], cp_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ee09a2-9dc4-4d55-b5b5-66a98c3734c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation between onset and summer AND fall precip\n",
    "# for NAM_var in NAM_var_list:\n",
    "#     calc_correlation(NAM_var=NAM_var, var='tp', months=[6, 7, 8, 9, 10, 11], cp_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d922cf6-de96-47b9-9604-7a9e2b0d7cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlation between onset and YEARLY precip\n",
    "# for NAM_var in NAM_var_list:\n",
    "#     calc_correlation(NAM_var=NAM_var, var='tp', months=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], cp_flag=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdd2985-452a-4ab1-88f6-de2098f449a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to calculate the correlation between\n",
    "# any 2 parameters over specified months\n",
    "def calc_var_correlation(var1='swvl1',var1_months=[3, 4, 5],\n",
    "                         var2='tp', var2_months=[6, 7, 8], var_region='dsw'):\n",
    "\n",
    "    # create list of months over which to average\n",
    "    var1_months_list = var1_months  # [int(m) for m in str(var1_months)]  # turn var integer into list (e.g. 678 -> [6,7,8])\n",
    "    var2_months_list = var2_months  # [int(m) for m in str(var2_months)]  # turn var integer into list (e.g. 678 -> [6,7,8])\n",
    "    # make string for month letters from var_range (e.g. [6,7,8] -> 'JJA')\n",
    "    var1_months = ''.join([calendar.month_name[m][0] for m in var1_months_list])\n",
    "    var2_months = ''.join([calendar.month_name[m][0] for m in var2_months_list])\n",
    "\n",
    "    # path to save figures\n",
    "    out_fn = f'corr_{var1}_{var1_months}_{var2}_{var2_months}_{var_region}.nc'\n",
    "    out_fp = os.path.join(corr_out_path, var_region, out_fn)\n",
    "\n",
    "    # check existence of file already\n",
    "    if os.path.exists(out_fp):\n",
    "        print(f'File already exists for: {out_fn}')\n",
    "        print('\\nSkipping . . .')\n",
    "        return\n",
    "\n",
    "    # get var1 files depending on var_region\n",
    "    if var_region == 'cp':\n",
    "        var1_files = glob.glob(f'{my_era5_path}{var_region}/*{var1}_198001_201912_cp.nc')\n",
    "    elif var_region == 'dsw':\n",
    "        var1_files = glob.glob(f'{my_era5_path}{var_region}/*/*{var1}_*_dsw.nc')\n",
    "    else:\n",
    "        print(f'var_region not found: {var_region}')\n",
    "        return\n",
    "\n",
    "    # get var2 files for dsw only\n",
    "    var2_files = glob.glob(f'{my_era5_path}{var_region}/*/*{var2}_*_dsw.nc')\n",
    "\n",
    "    # open datasets\n",
    "    var1_ds = xr.open_mfdataset(var1_files)\n",
    "    var2_ds = xr.open_mfdataset(var2_files)\n",
    "\n",
    "    # pull out actual variable name in the dataset since they can be different names/capitalized\n",
    "    var1_name = [v for v in var1_ds.data_vars.keys() if f'{var1.upper()}' in v][0]\n",
    "    var1_da = var1_ds[var1_name]\n",
    "    var2_name = [v for v in var2_ds.data_vars.keys() if f'{var2.upper()}' in v][0]\n",
    "    var2_da = var2_ds[var2_name]\n",
    "\n",
    "    # get data from var1\n",
    "    if 'AVG' in var1_name:\n",
    "        mon_mean = var1_da.resample(time='1M').mean()\n",
    "        var1_mon_mean = mon_mean.sel(time=mon_mean['time.month'].isin(var1_months_list))\n",
    "        var1_data = var1_mon_mean.groupby('time.year').mean(dim='time')\n",
    "    else:\n",
    "        mon_sum = var1_da.resample(time='1M').sum()\n",
    "        var1_mon_sum = mon_sum.sel(time=mon_sum['time.month'].isin(var1_months_list))\n",
    "        var1_data = var1_mon_sum.groupby('time.year').sum(dim='time')\n",
    "\n",
    "    # get data from var2\n",
    "    if 'AVG' in var2_name:\n",
    "        mon_mean = var2_da.resample(time='1M').mean()\n",
    "        var2_mon_mean = mon_mean.sel(time=mon_mean['time.month'].isin(var2_months_list))\n",
    "        var2_data = var2_mon_mean.groupby('time.year').mean(dim='time')\n",
    "    else:\n",
    "        mon_sum = var2_da.resample(time='1M').sum()\n",
    "        var2_mon_sum = mon_sum.sel(time=mon_sum['time.month'].isin(var2_months_list))\n",
    "        var2_data = var2_mon_sum.groupby('time.year').sum(dim='time')\n",
    "\n",
    "    # calculate correlation\n",
    "    var_corr = xr.corr(var1_data, var2_data, dim='year')\n",
    "\n",
    "    # save correlation as netcdf file\n",
    "    var_corr.to_netcdf(out_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f95cbc-01c8-4259-aec6-451afa5aa967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to calculate the correlation between the start of the monsoon averages over a certain region and other variables globally\n",
    "def calc_correlation_global(var='ttr', months=[3, 4, 5], NAM_var='onset'):\n",
    "\n",
    "    # create list of months over which to average\n",
    "    var_months_list = months  # [int(m) for m in str(months)]  # turn var integer into list (e.g. 678 -> [6,7,8])\n",
    "    # make string for month letters from var_range (e.g. [6,7,8] -> 'JJA')\n",
    "    var_months = ''.join([calendar.month_name[m][0] for m in var_months_list])\n",
    "\n",
    "    # path to save figures\n",
    "    out_fn = f'corr_{var}_{NAM_var}_{var_months}_global.nc'\n",
    "    out_fp = os.path.join(corr_out_path, 'global', out_fn)\n",
    "\n",
    "    # check existence of file already\n",
    "    if os.path.exists(out_fp):\n",
    "        print(f'File already exists for: {out_fn}')\n",
    "        print('\\nSkipping . . .')\n",
    "        return\n",
    "\n",
    "    # lat/lon range for averaging\n",
    "    lats = slice(38,28)\n",
    "    lons = slice(246, 256)\n",
    "    # open onset dataset\n",
    "    NAM_ds = xr.open_dataset(os.path.join(my_era5_path, f'dsw/NAM_{NAM_var}.nc'))\n",
    "    NAM_ds['year'] = NAM_ds['year'].dt.year  # convert to only year.  e.g. 2012-01-01 -> 2012\n",
    "\n",
    "    # extract data array of the NAM variable\n",
    "    if NAM_var == 'length':\n",
    "        NAM_da = NAM_ds['dayofyear']\n",
    "        NAM_data = NAM_da.astype('float32')\n",
    "    else:\n",
    "        NAM_da = NAM_ds['date']\n",
    "        NAM_data = NAM_da.dt.dayofyear.astype('float32')\n",
    "\n",
    "    # select region and calculate mean\n",
    "    NAM_avg = NAM_data.sel(latitude=lats, longitude=lons).mean(dim=['latitude', 'longitude'])\n",
    "\n",
    "    # open var dataset\n",
    "    var_files = glob.glob(f'{my_era5_path}global/*/*{var}_*_dsw.nc')\n",
    "\n",
    "    var_ds = xr.open_mfdataset(var_files)\n",
    "\n",
    "    # pull out actual variable name in the dataset since they can be different names/capitalized\n",
    "    var_name = [v for v in var_ds.data_vars.keys() if f'{var.upper()}' in v][0]\n",
    "    var_da = var_ds[var_name]\n",
    "\n",
    "    # get data from var\n",
    "    if 'AVG' in var_name:\n",
    "        mon_mean = var_da.resample(time='1M').mean()\n",
    "        var_mon_mean = mon_mean.sel(time=mon_mean['time.month'].isin(var_months_list))\n",
    "        var_data = var_mon_mean.groupby('time.year').mean(dim='time')\n",
    "    else:\n",
    "        mon_sum = var_da.resample(time='1M').sum()\n",
    "        var_mon_sum = mon_sum.sel(time=mon_sum['time.month'].isin(var_months_list))\n",
    "        var_data = var_mon_sum.groupby('time.year').sum(dim='time')\n",
    "\n",
    "    # calculate correlation\n",
    "    var_corr = xr.corr(NAM_avg, var_data, dim='year')\n",
    "\n",
    "    # save correlation as netcdf file\n",
    "    var_corr.to_netcdf(out_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cecb4b-e419-4fb8-bc2e-222f23f348d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate correlations for ttr\n",
    "vars = ['ttr', 'sstk']\n",
    "months_list = [\n",
    "    [3],\n",
    "    [4],\n",
    "    [5],\n",
    "    [6],\n",
    "    [7],\n",
    "    [8],\n",
    "    [3, 4, 5],\n",
    "    [6, 7, 8],\n",
    "]\n",
    "NAM_var_list = ['onset', 'retreat', 'length']\n",
    "for var in vars:\n",
    "    for months in months_list:\n",
    "        for NAM_var in NAM_var_list:\n",
    "            with open(f'{der_script_path}gobal.txt', 'a') as file:\n",
    "                file.write(f'{var} - {months} - {NAM_var}\\n')\n",
    "            calc_correlation_global(var=var, months=months, NAM_var=NAM_var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-mland_xr]",
   "language": "python",
   "name": "conda-env-.conda-mland_xr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
