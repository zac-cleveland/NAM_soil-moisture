{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e158896-bb9b-4409-9135-53a5fc849103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import numpy.matlib\n",
    "import datetime\n",
    "import xarray as xr\n",
    "from scipy import interpolate\n",
    "from numpy import ma\n",
    "from scipy import stats\n",
    "import scipy.io as sio\n",
    "import pickle as pickle\n",
    "from sklearn import linear_model\n",
    "import numpy.ma as ma\n",
    "import matplotlib.patches as mpatches\n",
    "from shapely.geometry.polygon import LinearRing\n",
    "\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "\n",
    "from copy import copy \n",
    "\n",
    "# Plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from mpl_toolkits.axes_grid1.axes_divider import HBoxDivider\n",
    "import mpl_toolkits.axes_grid1.axes_size as Size\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "# OS interaction\n",
    "import os\n",
    "import sys\n",
    "import cftime\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.util import add_cyclic_point\n",
    "\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "import IPython.core.display as di # Example: di.display_html('<h3>%s:</h3>' % str, raw=True)\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import glob\n",
    "import dask\n",
    "import dask.bag as db\n",
    "\n",
    "from scipy import interpolate\n",
    "\n",
    "import statsmodels.stats.multitest as multitest\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from cartopy.crs import EqualEarth, PlateCarree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "629946cd-81f1-432d-b51f-1ae716d16f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_path = '/glade/campaign/collections/rda/data/ds633.0/'\n",
    "out_path = '/glade/u/home/zcleveland/scratch/ERA5/dsw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75548019-a034-4361-a9ae-bf3a5625e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add other variables and their corresponding subdirectories here\n",
    "# var_list = [\n",
    "#     'lsp', # large scale precipitation\n",
    "#     'cp', # convective precipitation\n",
    "#     'sd', # snow depth\n",
    "#     'msl', # mean sea level pressure\n",
    "#     'tcc', # total cloud cover\n",
    "#     'stl1', # soil temp layer 1\n",
    "#     'stl2', # soil temp layer 2\n",
    "#     'stl3', # soil temp layer 3\n",
    "#     'stl4', # soil temp layer 4\n",
    "#     'swvl1', # soil volume water content layer 1\n",
    "#     'swvl2', # soil volume water content layer 2\n",
    "#     'swvl3', # soil volume water content layer 3\n",
    "#     'swvl4', # soil volume water content layer 4\n",
    "#     '2t', # 2 meter temp\n",
    "#     '2d', # 2 meter dew point\n",
    "#     'ishf', # instant surface heat flux\n",
    "#     'ie', # instant moisture flux\n",
    "# ]\n",
    "# Input parameters for desert southwest\n",
    "lat_range = slice(40, 20)\n",
    "lon_range = slice(240, 260)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca4642ee-e180-48fa-93ce-9fd44476396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract, subset, and process data for single variable in the desert southwest\n",
    "def dsw_subset_era5(variable='lsp', start_date=200101, end_date=200102):\n",
    "    print(f'Processing variable: {variable}: {start_date}_{end_date}\\n')\n",
    "\n",
    "    # exit if not yearly data\n",
    "    if (end_date-start_date)>11: \n",
    "        print(f'Time range greater than 1 year. Skipping... ')\n",
    "        print(f'start_date: {start_date}\\n end_date: {end_date}\\n')\n",
    "        return\n",
    "    \n",
    "    start_time = time.time() # keep track of time to process.\n",
    "    start_year, start_month = f'{start_date}'[:4], f'{start_date}'[4:]\n",
    "    end_year, end_month = f'{end_date}'[:4], f'{end_date}'[4:]\n",
    "    # define output filename and path\n",
    "    out_fn = f'{variable}_{start_date}_{end_date}_dsw'\n",
    "    out_fp = os.path.join(out_path, out_fn)\n",
    "\n",
    "    # check if file already exists\n",
    "    if (os.path.exists(f'{out_fp}.nc') or \n",
    "        os.path.exists(f'{out_fp}_min.nc') or \n",
    "        os.path.exists(f'{out_fp}_max.nc') or\n",
    "        os.path.exists(f'{out_fp}_avg.nc')):\n",
    "        \n",
    "        print(f'File {out_fn} already exists. Skipping...\\n')\n",
    "        return\n",
    "    \n",
    "    # find the directory that the variable exists in\n",
    "    print(f'Searching for {var} in {era5_path}\\n')\n",
    "    contents = os.listdir(era5_path)\n",
    "    directories = [item for item in contents if os.path.isdir(os.path.join(era5_path, item))]\n",
    "    found = []\n",
    "    for dir in directories:    \n",
    "        files = os.listdir(f'{era5_path}{dir}/{197901}')\n",
    "        for file in files:\n",
    "            if f'_{variable}.' in file:\n",
    "                print(f'{var} found at {dir}\\n')\n",
    "                found.append(1)\n",
    "                var_dir = dir\n",
    "                break\n",
    "        if found:\n",
    "            break\n",
    "    if not found:\n",
    "        print(f'No files found with {variable}. Skipping...\\n')\n",
    "        return\n",
    "        \n",
    "    # find files for the variable in the specified directory\n",
    "    files = []\n",
    "    for year in range(int(start_year), int(end_year)+1):\n",
    "        for month in range(1,13):\n",
    "            if month<10:\n",
    "                year_month = f'{year}0{month}'\n",
    "            else:\n",
    "                year_month = f'{year}{month}'\n",
    "            try:\n",
    "                if ((f'{year_month}' < f'{start_date}') or (f'{year_month}' > f'{end_date}')):\n",
    "                    pass\n",
    "                else:\n",
    "                    files += glob.glob(f'{era5_path}/{var_dir}/{year_month}/*_{variable}.*.nc', recursive=True)\n",
    "            except Exception as e:\n",
    "                print(f'Error in {era5_path}/{var_dir}/{year}0{month}/*_{variable}.*.nc: {e}\\n')\n",
    "    files.sort()\n",
    "\n",
    "    # calculate total number of directories for sanity check\n",
    "    total_directories = len(files)\n",
    "    print(f'{total_directories} number of files\\n')\n",
    "    \n",
    "    # create a list to hold data for each month\n",
    "    with dask.config.set(**{'array.slicing.split_large_chunks': True}):\n",
    "        data_list = []\n",
    "        print(f'opening datasets')\n",
    "        data_list.append(xr.open_mfdataset(files))\n",
    "\n",
    "        # check if there are actually any files\n",
    "        if not data_list:\n",
    "            print(f'No files found for variable: {variable}')\n",
    "            print(f'\\rTime elapsed: {time.time()-start_time: .2f} s\\n')\n",
    "            return\n",
    "\n",
    "        # concatenate data for all months into single xarray and subset\n",
    "        print(f'Combining Data')\n",
    "        combined_data = xr.merge(data_list)\n",
    "        ds_sub = combined_data.sel(latitude=lat_range, longitude=lon_range, drop=True)\n",
    "        \n",
    "        ### FOR ACCUMULCATIONS ###\n",
    "        if sorted(ds_sub.dims) == ['forecast_hour', 'forecast_initial_time', 'latitude', 'longitude']:\n",
    "            # calculate sum total\n",
    "            daily_data = ds_sub.sum(dim='forecast_hour').resample(forecast_initial_time='1D').sum()\n",
    "            daily_data = daily_data.rename({'forecast_initial_time': 'time'})\n",
    "            # write data to NetCDF file\n",
    "            print(f'Writing data to NetCDF\\n')\n",
    "            daily_data.to_netcdf(f'{out_fp}.nc')\n",
    "\n",
    "        ### FOR DAILY AVERAGE, MIN, AND MAX\n",
    "        elif sorted(ds_sub.dims) == ['latitude', 'longitude', 'time']:\n",
    "            # calculate daily average, min, and max\n",
    "            temp = ds_sub.resample(time='1D')\n",
    "            daily_avg = temp.mean(dim='time')\n",
    "            daily_min = temp.min(dim='time')\n",
    "            daily_max = temp.max(dim='time')\n",
    "            # write data to NetCDF file\n",
    "            print(f'Writing data to NetCDF\\n')\n",
    "            daily_avg.to_netcdf(f'{out_fp}_avg.nc')\n",
    "            daily_min.to_netcdf(f'{out_fp}_min.nc')\n",
    "            daily_max.to_netcdf(f'{out_fp}_max.nc')\n",
    "            \n",
    "        else:\n",
    "            print(F'Dimensional error finding daily values for {var}') \n",
    "            print(f'Dimensions are {sorted(ds_sub.dims)}.\\n Skipping...\\n')\n",
    "            return\n",
    "\n",
    "\n",
    "        print(f'\\rTime elapsed: {time.time()-start_time: .2f} s\\n')\n",
    "\n",
    "    #return combined_data, ds_sub, ds_sub_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bdbe023d-74c7-4058-98bb-b23928a0e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set time array to loop through\n",
    "years = np.arange(1980,2020)\n",
    "months = np.arange(1,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "579cb813-938c-427f-a477-0a0ace606405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing variable: lsp: 198001_198002\n",
      "\n",
      "Searching for lsp in /glade/campaign/collections/rda/data/ds633.0/\n",
      "\n",
      "lsp found at e5.oper.fc.sfc.accumu\n",
      "\n",
      "4 number of files\n",
      "\n",
      "opening datasets\n",
      "Combining Data\n",
      "Writing data to NetCDF\n",
      "\n",
      "Time elapsed:  24.53 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop through variables in var_directories and process each one\n",
    "for var in var_list:\n",
    "    for year in years:\n",
    "        start_date = int(f'{year}01')\n",
    "        end_date = int(f'{year}12')\n",
    "        dsw_subset_era5(var, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43264879-0774-489f-9259-8caa1f0c983e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-mland_xr]",
   "language": "python",
   "name": "conda-env-.conda-mland_xr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
