{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2842f6fb-0b3b-4f0a-a60a-0d5ca43bc650",
   "metadata": {},
   "source": [
    "This script is used to subset ERA5 data by lat/lon and time (e.g., daily averages). Pressure level variables will be subset and saved in 1 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a5cbe72-092b-4d9f-abf8-a59c35c7e870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions\n",
    "# OS interaction and time\n",
    "import os\n",
    "import sys\n",
    "import cftime\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "import dask\n",
    "import dask.bag as db\n",
    "import calendar\n",
    "import importlib\n",
    "\n",
    "# math and data\n",
    "import math\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import scipy as sp\n",
    "import scipy.linalg\n",
    "from scipy.signal import detrend\n",
    "import pandas as pd\n",
    "import pickle as pickle\n",
    "from sklearn import linear_model\n",
    "import statsmodels.stats.multitest as multitest\n",
    "\n",
    "# random\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "import IPython.core.display as di # Example: di.display_html('<h3>%s:</h3>' % str, raw=True)\n",
    "\n",
    "# paths to various directories\n",
    "rda_era5_path = '/glade/campaign/collections/rda/data/ds633.0/'  # base path to ERA5 data on derecho\n",
    "my_era5_path = '/glade/u/home/zcleveland/scratch/ERA5/'  # path to subset data\n",
    "misc_data_path = '/glade/u/home/zcleveland/scratch/misc_data/'  # path to misc data\n",
    "scripts_main_path = '/glade/u/home/zcleveland/NAM_soil-moisture/scripts_main/'  # path to my dicts, lists, and functions\n",
    "\n",
    "# import variable lists and dictionaries\n",
    "if scripts_main_path not in sys.path:\n",
    "    sys.path.insert(0, scripts_main_path)  # path to file containing these lists/dicts\n",
    "if 'my_dictionaries' in sys.modules:\n",
    "    importlib.reload(sys.modules['my_dictionaries'])\n",
    "# import my lists and dictionaries\n",
    "from my_dictionaries import var_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d614eb2d-5396-4ee7-9b1a-a869b9a20d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables to subset\n",
    "# SFC instantaneous variables\n",
    "sfc_instan_vars = [\n",
    "    # 'sd',  # snow depth  (m of water equivalent)\n",
    "    # 'msl',  # mean sea level pressure (Pa)\n",
    "    # 'stl1',  # soil temp layer 1 (K)\n",
    "    # 'swvl1',  # soil volume water content layer 1 (m^3 m^-3)\n",
    "    # '2t',  # 2 meter temp (K)\n",
    "    # '2d',  # 2 meter dew point (K)\n",
    "    # 'cape',  # convective available potential energy (J kg^-1)\n",
    "    # 'tcw',  # total column water (kg m^-2) -- sum total of solid, liquid, and vapor in a column\n",
    "    # 'sstk',  # sea surface temperature (K)\n",
    "    # 'viwve',  # vertical integral of eastward water vapour flux (kg m^-1 s^-1) - positive south -> north\n",
    "    # 'viwvn',  # vertical integral of northward water vapour flux (kg m^-1 s^-1) - positive west -> east\n",
    "    # 'viwvd',  # vertical integral of divergence of moisture flux (kg m^-2 s^-1) - positive divergencve\n",
    "]\n",
    "\n",
    "# surface accumulation variables\n",
    "sfc_accumu_vars = [\n",
    "    # 'lsp',  # large scale precipitation (m of water)\n",
    "    # 'cp',  # convective precipitation (m of water)\n",
    "    # 'sshf',  # surface sensible heat flux (J m^-2)\n",
    "    # 'slhf',  # surface latent heat flux (J m^-2)\n",
    "    # 'ssr',  # surface net solar radiation (J m^-2)\n",
    "    # 'str',  # surface net thermal radiation (J m^-2)\n",
    "    # 'sf',  # total snowfall (m of water equivalent)\n",
    "    # 'ssrd',  # surface solar radiation downwards (J m^-2)\n",
    "    # 'strd',  # surface thermal radiation downwards (J m^-2)\n",
    "    # 'ttr',  # top net thermal radiation (OLR, J m^-2) -- divide by time (s) for W m^-2\n",
    "]\n",
    "\n",
    "# pressure level variables\n",
    "pl_vars = [\n",
    "    'z',  # geopotential (m^2 s^2)\n",
    "    # 't',  # temperature (K)\n",
    "    # 'u',  # u component of wind(m s^-1)\n",
    "    # 'v',  # v component of wind (m s^-1)\n",
    "    # 'q',  # specific humidity (kg kg^-1)\n",
    "]\n",
    "\n",
    "regions = {\n",
    "    'dsw': {'latitude': slice(40, 20), 'longitude': slice(240, 260)},\n",
    "    'WestUS_Mexico': {'latitude': slice(50, 10), 'longitude': slice(230, 270)},\n",
    "    'global': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c17c115e-e74e-4684-9373-f86098825e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_var_directory(var, rda_era5_path):\n",
    "    contents = os.listdir(rda_era5_path)  # all contents in rda_era5_path\n",
    "    # only get directories from rda_era5_path  - disclude invariant directory\n",
    "    directories = [item for item in contents if os.path.isdir(os.path.join(rda_era5_path, item)) and item != 'e5.oper.invariant']\n",
    "    for dir in directories:\n",
    "        files = os.listdir(os.path.join(rda_era5_path, dir, '197901'))\n",
    "        for file in files:\n",
    "            if f'_{var}.' in file:  # check for existence of the var key in the file names\n",
    "                return dir\n",
    "    raise FileNotFoundError(f\"var: {var} not found in {rda_era5_path}\")  # if no file found containing var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e5edb4b-ac52-48fe-8ffd-a6177f0ffd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_out_fn(var, region, year, month):\n",
    "    return f'{var}_{year}{month:02d}_{region}.nc' if month else f'{var}_{year}01_{year}12_{region}.nc'\n",
    "\n",
    "\n",
    "def get_out_fp(region, year, out_fn):\n",
    "    return os.path.join(my_era5_path, region, f'{year}', out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c5c4d61-c85d-4f07-982c-be9f1d8f669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_var_files(var, year, month, var_base_dir):\n",
    "    month_pattern = f'{year}{month:02d}' if month else f'{year}*'\n",
    "    file_pattern = os.path.join(rda_era5_path, var_base_dir, month_pattern, f'*_{var}.*.nc')\n",
    "    files = sorted(glob.glob(file_pattern))\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"files not found for {var} in {var_base_dir}\")\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbb8b235-cd91-40a6-b5cf-0392b23a2486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_lat_lon(ds, region):\n",
    "    region_slice = regions.get(region)\n",
    "    if region_slice:\n",
    "        ds =  ds.sel(latitude=region_slice['latitude'], longitude=region_slice['longitude'], drop=True)\n",
    "    elif region == 'global':\n",
    "        pass  # bad form, but I want the extra check to make sure I'm not crazy here......\n",
    "    else:\n",
    "        raise ValueError(f\"Not a valid region: {region}\")\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1194f939-cb75-4cf1-9415-1a28cb913476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_pl(var_ds, **kwargs):\n",
    "    var_ds = var_ds.sel(level=kwargs.get('pl_levels', [1000, 850, 700, 500, 300]))\n",
    "    return var_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "099b9dcd-43b3-485c-a5dc-2ad3d4a0b539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_daily_values(var, da, **kwargs):\n",
    "    if var in sfc_instan_vars or var in pl_vars:\n",
    "        da_daily = da.resample(time='1D').mean('time', skipna=True)\n",
    "    elif var in sfc_accumu_vars:\n",
    "        da_daily = da.sum('forecast_hour', skipna=True).resample(forecast_initial_time='1D').sum(skipna=True).rename({'forecast_initial_time': 'time'})\n",
    "    else:\n",
    "        raise ValueError(f\"Not able to compute daily values for: {var}.\")\n",
    "    return da_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afff624e-77c0-4b83-922f-3d4c1fcc6d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_var_data(var, region, year, month, var_base_dir, **kwargs):\n",
    "    # get var files for current year\n",
    "    var_files = find_var_files(var, year, month, var_base_dir)\n",
    "\n",
    "    # open datasets\n",
    "    if var not in pl_vars:\n",
    "        chunks = {'time': 24} if var not in sfc_accumu_vars else {'forecast_initial_time': 1, 'forecast_hour': 12}\n",
    "    else:\n",
    "        chunks = {'time': 24, 'level': 1}\n",
    "    var_ds = xr.open_mfdataset(var_files, chunks=chunks, parallel=True)  # chunk by daily\n",
    "\n",
    "    # subset by latitude/longitude\n",
    "    var_ds = subset_lat_lon(var_ds, region)\n",
    "\n",
    "    # subset by pressure level\n",
    "    if var in pl_vars:\n",
    "        var_ds = subset_pl(var_ds, **kwargs)\n",
    "\n",
    "    # pull out variable name in actual dataset since they can be different\n",
    "    var_name = [v for v in var_ds.data_vars.keys() if f'{var.upper()}' in v.upper()][0]\n",
    "    var_da = var_ds[var_name]\n",
    "\n",
    "    # compute daily values\n",
    "    var_daily = calc_daily_values(var, var_da)\n",
    "    return var_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe1b6634-8aa4-4dbc-9807-95814e01899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(var, region='dsw', year=1980, month=None, **kwargs):\n",
    "\n",
    "    # find file base path in the rda dataset directory\n",
    "    var_base_dir = find_var_directory(var, rda_era5_path)\n",
    "    if not var_base_dir:\n",
    "        raise ValueError(f\"var_base_dir not found\")\n",
    "\n",
    "    # make output file name and path for saving\n",
    "    out_fn = get_out_fn(var, region, year, month)\n",
    "    out_fp = get_out_fp(region, year, out_fn)\n",
    "\n",
    "    # check existence of file already\n",
    "    if os.path.exists(out_fp):\n",
    "        print(f\"\\nfile already exists for: {out_fn}.\")\n",
    "        if not kwargs.get('overwrite_flag', False):\n",
    "            raise ValueError(\"overwrite_flag is False, set to True to overwrite. Skipping . . .\")\n",
    "        else:\n",
    "            print(\"\\noverwrite_flag is True. Overwriting . . .\")\n",
    "\n",
    "    # process data\n",
    "    var_daily = process_var_data(var, region, year, month, var_base_dir, **kwargs)\n",
    "    # save or return data\n",
    "    if kwargs.get('save_nc', False):\n",
    "        var_daily.to_netcdf(out_fp)\n",
    "    else:\n",
    "        return var_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78377182-03c3-4201-85ca-3178f5b560d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test cell to check data processed correctly\n",
    "# if __name__ == '__main__':\n",
    "#     # args\n",
    "#     region = 'WestUS_Mexico'\n",
    "#     years = np.arange(1980,2020)\n",
    "#     months = np.arange(1,13)\n",
    "#     levels = [1000, 850, 700, 500, 300]\n",
    "\n",
    "#     # kwargs\n",
    "#     main_kwargs = {\n",
    "#     'save_nc': True,\n",
    "#     'overwrite_flag': False,\n",
    "#     }\n",
    "\n",
    "#     # set variable\n",
    "#     var = 'z'\n",
    "#     kwargs = main_kwargs.copy()\n",
    "#     if var in pl_vars:  # add levels to kwargs if var is a pl var\n",
    "#         kwargs.update({'pl_levels': levels})\n",
    "#     print(f\"\\n\\n{'- - '*20}\\n\\t\\tProcessing: {var_dict[var]} {kwargs.get('pl_levels', '')}\\n{'- - '*20}\")\n",
    "\n",
    "#     # set year\n",
    "#     year = 1980\n",
    "#     print(f\"\\n{year}: \", end='')\n",
    "#     # set months\n",
    "#     # month = None\n",
    "#     month = 12\n",
    "#     try:\n",
    "#         if kwargs.get('save_nc', False):\n",
    "#             main(var, region=region, year=year, month=month, **kwargs)\n",
    "#         else:\n",
    "#             var_da = main(var, region=region, year=year, month=month, **kwargs)\n",
    "#     except Exception as e:\n",
    "#         print(f\"\\nException raised: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f87d194-d5a5-44a9-9a12-ae45ff9aeef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # call main function to subset non pressure level data (yearly)\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "#     # args\n",
    "#     region = 'WestUS_Mexico'\n",
    "#     years = np.arange(1980,2020)\n",
    "#     levels = [1000, 850, 700, 500, 300]\n",
    "\n",
    "#     # kwargs\n",
    "#     main_kwargs = {\n",
    "#     'overwrite_flag': False,\n",
    "#     }\n",
    "\n",
    "#     # set up list of variables to process\n",
    "#     var_list = sfc_instan_vars + sfc_accumu_vars\n",
    "#     # loop through vars\n",
    "#     for i, var in enumerate(var_list, start=1):\n",
    "#         kwargs = main_kwargs.copy()\n",
    "        \n",
    "#         if var in pl_vars:  # add levels to kwargs if var is a pl var\n",
    "#             kwargs.update({'pl_levels': levels})\n",
    "#         print(f\"\\n\\n{'- - '*20}\\n\\t\\tProcessing var {i} of {len(var_list)}: {var_dict[var]}\\n{'- - '*20}\\n\")\n",
    "\n",
    "#         for year in years:\n",
    "#             print(f\"{year}...\", end='')\n",
    "#             try:\n",
    "#                 main(var, region=region, year=year, **kwargs)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"\\nException raised: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5290247-9dc0-4ce7-bb82-905d5bae7c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call main function to subset pressure level data (monthly)\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    # args\n",
    "    region = 'WestUS_Mexico'\n",
    "    years = np.arange(1980,2020)\n",
    "    months = np.arange(1,13)\n",
    "    levels = [1000, 850, 700, 500, 300]\n",
    "\n",
    "    # kwargs\n",
    "    main_kwargs = {\n",
    "    'save_nc': True,\n",
    "    'overwrite_flag': False,\n",
    "    }\n",
    "\n",
    "    # set up list of variables to process\n",
    "    var_list = pl_vars\n",
    "    # loop through vars\n",
    "    for i, var in enumerate(var_list, start=1):\n",
    "        kwargs = main_kwargs.copy()\n",
    "        \n",
    "        if var in pl_vars:  # add levels to kwargs if var is a pl var\n",
    "            kwargs.update({'pl_levels': levels})\n",
    "        print(f\"\\n\\n{'- - '*20}\\n\\t\\tProcessing var {i} of {len(var_list)}: {var_dict[var]}\\n{'- - '*20}\", flush=True)\n",
    "\n",
    "        for year in years:\n",
    "            print(f\"\\n{year}: \", end='', flush=True)\n",
    "            for month in months:\n",
    "                print(f\" {month}...\", end='', flush=True)\n",
    "                try:\n",
    "                    main(var, region=region, year=year, month=month, **kwargs)\n",
    "                except Exception as e:\n",
    "                    print(f\"\\nException raised: {e}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8efbb6c-6e89-4bf0-a051-a1a521769f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_small_files(base_dir, size_threshold=1 * 1024 * 1024):  # 1 MB threshold\n",
    "#     small_files = []\n",
    "#     for subdir, _, files in os.walk(base_dir):\n",
    "#         for file in files:\n",
    "#             if file.endswith('.nc'):\n",
    "#                 file_path = os.path.join(subdir, file)\n",
    "#                 file_size = os.path.getsize(file_path)\n",
    "#                 if file_size < size_threshold:\n",
    "#                     small_files.append((file_path, file_size))\n",
    "\n",
    "#     return small_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ccc3d12-63d8-4caa-a292-2d10e9821a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def check_for_files(vars, region):\n",
    "#     missing_files = {}\n",
    "#     if not isinstance(vars, list):\n",
    "#         vars = [vars]\n",
    "#     for var in vars:\n",
    "#         missing_files[f'{var}_{region}'] = []\n",
    "#         for year in range(1980,2020):\n",
    "#             fn = get_out_fn(var, region, year)\n",
    "#             fp = get_out_fp(region, year, fn)\n",
    "#             if not os.path.exists(fp):\n",
    "#                 missing_files[f'{var}_{region}'].append(f'{year}')\n",
    "#     return missing_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7d126c-6897-4234-88e6-9b48014049ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run find_small_files to check for incomplete files\n",
    "# if __name__ == '__main__':\n",
    "#     base_dir = '/glade/u/home/zcleveland/scratch/ERA5/WestUS_Mexico/'\n",
    "#     small_files = find_small_files(base_dir)\n",
    "    \n",
    "#     for file_path, file_size in small_files:\n",
    "#         print(f\"{file_path}: {file_size} bytes\")\n",
    "\n",
    "#     missing_files = check_for_files(sfc_instan_vars+sfc_accumu_vars+pl_vars, 'WestUS_Mexico')\n",
    "#     for var, year in missing_files.items():\n",
    "#         if missing_files[f'{var}']:\n",
    "#             print(f'{var}: {year}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-mland_xr]",
   "language": "python",
   "name": "conda-env-.conda-mland_xr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
