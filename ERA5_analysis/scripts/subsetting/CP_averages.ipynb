{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd62bd65-aeed-464c-846d-544e4fd5b125",
   "metadata": {},
   "source": [
    "This script loops through the subset desert southwest data previosly extracted, and computes the mean or sum of different variables over the Colorado Plateau (CP).  This will be used as the \"average\" or \"cumulative\" conditions of the Colorado Plateau region to compare to each other lat/lon point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cce73cec-0bff-4610-8b2e-a4f72f1224ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functions\n",
    "# OS interaction and time\n",
    "import os\n",
    "import sys\n",
    "import cftime\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "import dask\n",
    "import dask.bag as db\n",
    "import calendar\n",
    "\n",
    "# math and data\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import xarray as xr\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import pickle as pickle\n",
    "from sklearn import linear_model\n",
    "import matplotlib.patches as mpatches\n",
    "from shapely.geometry.polygon import LinearRing\n",
    "import statsmodels.stats.multitest as multitest\n",
    "\n",
    "# plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from mpl_toolkits.axes_grid1.axes_divider import HBoxDivider\n",
    "import mpl_toolkits.axes_grid1.axes_size as Size\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.util import add_cyclic_point\n",
    "\n",
    "# random\n",
    "from IPython.display import display\n",
    "from IPython.display import HTML\n",
    "import IPython.core.display as di # Example: di.display_html('<h3>%s:</h3>' % str, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d306e273-c0da-4929-bfbc-95437ec9f545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify directories\n",
    "data_in_path = '/glade/u/home/zcleveland/scratch/ERA5/'  # path to subsetted data\n",
    "data_out_path = '/glade/u/home/zcleveland/scratch/ERA5/cp/'  # path to the Colorado Plateau data\n",
    "esa_out_path = '/glade/u/home/zcleveland/scratch/ESA_data/cp/'  # path to Colorado Plateau ESA data\n",
    "esa_in_path = '/glade/u/home/zcleveland/scratch/ESA_data/dsw/'  # path to ESA dsw data\n",
    "sub_script_path = '/glade/u/home/zcleveland/NAM_soil-moisture/ERA5_analysis/scripts/subsetting/'  # path to subsetting scripts\n",
    "plot_script_path = '/glade/u/home/zcleveland/NAM_soil-moisture/ERA5_analysis/scripts/plotting/' # path to plotting scripts\n",
    "fig_out_path = '/glade/u/home/zcleveland/NAM_soil-moisture/ERA5_analysis/plots/'  # path to generated figures\n",
    "temp_scratch_path = '/glade/u/home/zcleveland/NAM_soil-moisture/ERA5_analysis/temp/'  # path to temp directory in scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f68d22-4f3a-48f3-9276-b6e6f2092197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define list of variables\n",
    "var_list = [\n",
    "    'lsp',  # large scale precipitation (m of water) - accumu\n",
    "    'cp',  # convective precipitation (m of water) - accumu\n",
    "    'tp',  # total precipitation (m of water) - accumu -- DERIVED\n",
    "    'sd',  # snow depth  (m of water equivalent) - instan\n",
    "    'msl',  # mean sea level pressure (Pa) - instan\n",
    "    'tcc',  # total cloud cover (0-1) - instan\n",
    "    'stl1',  # soil temp layer 1 (K) - instan\n",
    "    'stl2',  # soil temp layer 2 (K) - instan\n",
    "    'stl3',  # soil temp layer 3 (K) - instan\n",
    "    'stl4',  # soil temp layer 4 (K) - instan\n",
    "    'swvl1',  # soil volume water content layer 1 (m^3 m^-3) - instan\n",
    "    'swvl2',  # soil volume water content layer 2 (m^3 m^-3) - instan\n",
    "    'swvl3',  # soil volume water content layer 3 (m^3 m^-3) - instan\n",
    "    'swvl4',  # soil volume water content layer 4 (m^3 m^-3) - instan\n",
    "    '2t',  # 2 meter temp (K) - instan\n",
    "    '2d',  # 2 meter dew point (K) - instan\n",
    "    'ishf',  # instant surface heat flux (W m^-2) - instan\n",
    "    'ie',  # instant moisture flux (kg m^-2 s^-1) - instan\n",
    "    'sshf',  # surface sensible heat flux (J m^-2) - accumu\n",
    "    'slhf',  # surface latent heat flux (J m^-2) - accumu\n",
    "    'ssr',  # surface net solar radiation (J m^-2) - accumu\n",
    "    'str',  # surface net thermal radiation (J m^-2) - accumu\n",
    "    'sro',  # surface runoff (m) - accumu\n",
    "    'sf',  # total snowfall (m of water equivalent) - accumu\n",
    "    'cape',  # convective available potential energy (J kg^-1) - instan\n",
    "    'tcw',  # total column water (kg m^-2) - sfc (sum total of solid, liquid, and vapor in a column)\n",
    "    'ssrd',  # surface solar radiation downwards (J m^-2) - accumu\n",
    "    'strd',  # surface thermal radiation downwards (J m^-2) - accumu\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "142e4008-7db2-431d-adf8-cea6529afa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to compute and save CP averages of ERA5 Desert Southwest Variables\n",
    "def cp_subsetting_monthly(var='tp', regrid_flag=False, esa_flag=False, overwrite_flag=False):\n",
    "    if (regrid_flag & esa_flag):\n",
    "        print('regrid_flag and esa_flag cannot both be set to True:')\n",
    "        print(f'regrid_flag: {regrid_flag}')\n",
    "        print(f'esa_flag: {esa_flag}')\n",
    "        return\n",
    "    # create filename, filepath, and check their existence\n",
    "    if regrid_flag:\n",
    "        out_fn = f'{var}_regrid_198001_2019_cp.nc'\n",
    "        out_fp = os.path.join(data_out_path, out_fn)\n",
    "    elif esa_flag:\n",
    "        out_fn = f'{var}_esa_198001_201912_cp.nc'\n",
    "        out_fp = os.path.join(esa_out_path, out_fn)\n",
    "    else:\n",
    "        out_fn = f'{var}_198001_201912_cp.nc'\n",
    "        out_fp = os.path.join(data_out_path, out_fn)\n",
    "\n",
    "    if os.path.exists(out_fp):\n",
    "        if overwrite_flag:\n",
    "            pass\n",
    "        else:\n",
    "            print(f'{out_fn} already exists. Skipping . . .\\n')\n",
    "            return\n",
    "\n",
    "    # open datasets\n",
    "    if regrid_flag:\n",
    "        files = glob.glob(f'{data_in_path}regrid-to-esa/*/*{var}*.nc')\n",
    "    elif esa_flag:\n",
    "        files = glob.glob(f'{esa_in_path}*{var}*.nc')\n",
    "    else:\n",
    "        files = glob.glob(f'{data_in_path}dsw/*/*{var}*.nc')\n",
    "    files.sort()\n",
    "    var_ds = xr.open_mfdataset(files)\n",
    "\n",
    "    # pull out actual variable name in the dataset since they can be different names/capitalized\n",
    "    var_name = [v for v in var_ds.data_vars.keys() if f'{var[0].upper()}' in v.upper()][0]\n",
    "    var_da = var_ds[var_name]\n",
    "\n",
    "    # define lat/lon bounds of four corners to define Colorado Plateau\n",
    "    if (regrid_flag or esa_flag):\n",
    "        cp_lats = slice(39,35)\n",
    "        cp_lons = slice(-111,-107)\n",
    "    else:\n",
    "        cp_lats = slice(39,35)\n",
    "        cp_lons = slice(249,253)\n",
    "    cp_da = var_da.sel(latitude=cp_lats, longitude=cp_lons)\n",
    "\n",
    "    # sort by month and take average or sum\n",
    "    # averaged values (instantaneous in ERA5 or sm in ESA)\n",
    "    if (('AVG' in var_name) or ('sm' in var_name)):\n",
    "        cp_monthly_data = cp_da.resample(time='1M').mean(dim=['time', 'latitude', 'longitude'])\n",
    "        # rename variable to include CP\n",
    "        cp_monthly_data = cp_monthly_data.to_dataset().rename(\n",
    "            {f'{var_name}': f'{var_name}_CP'}\n",
    "        )\n",
    "    # summed values (accumulated in ERA5)\n",
    "    else:\n",
    "        cp_monthly_data = cp_da.resample(time='1M').sum(dim=['time', 'latitude', 'longitude'])\n",
    "        # rename variable to include CP\n",
    "        cp_monthly_data = cp_monthly_data.to_dataset().rename(\n",
    "            {f'{var_name}': f'{var_name}_CP'}\n",
    "        )\n",
    "\n",
    "    # save to netcdf file\n",
    "    cp_monthly_data.to_netcdf(out_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2476b8ae-9f3a-43cb-b255-a19f3e1882f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsw original values\n",
    "if __name__ == '__main__':\n",
    "    for var in var_list:\n",
    "        cp_subsetting_monthly(var=var, regrid_flag=False, overwrite_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50c9ab4-f425-4274-b6ae-30c6ac27194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dsw regridded values\n",
    "if __name__ == '__main__':\n",
    "    for var in var_list:\n",
    "        cp_subsetting_monthly(var=var, regrid_flag=True, overwrite_flag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74eb06b2-5005-44d5-b860-ddad72184b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# esa data\n",
    "if __name__ == '__main__':\n",
    "    cp_subsetting_monthly(var='sm', esa_flag=True, overwrite_flag=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-mland_xr]",
   "language": "python",
   "name": "conda-env-.conda-mland_xr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
